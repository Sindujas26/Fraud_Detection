{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional File No.2  - Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <font color='purple'> \n",
    "    \n",
    "    \n",
    "  This file contains some <b> Data Sampling Algorithms </b>. These algorithms are run here and then loaded into the oringinal file using joblib inorder take advantage of parallel running of algorithms as this saves time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# for the Q-Q plots\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# for preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine import missing_data_imputers as mdi\n",
    "from feature_engine import variable_transformers as vt\n",
    "from feature_engine import outlier_removers as outr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# for the model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# ensembling Algorithms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from  sklearn.ensemble import ExtraTreesClassifier\n",
    "from  sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\jayas\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jayas\\anaconda3\\lib\\site-packages (from xgboost) (1.16.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\jayas\\anaconda3\\lib\\site-packages (from xgboost) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\jayas\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\jayas\\anaconda3\\lib\\site-packages (from imblearn) (0.6.2)\n",
      "Requirement already satisfied: scipy>=0.17 in c:\\users\\jayas\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\jayas\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.22.2.post1)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\jayas\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.16.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jayas\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for unbalanced dataset\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# for oversampling to ensure balanced datasets\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')  \n",
    "test= pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling Algorithms - Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.88\n",
      "Best parameters: {'model__criterion': 'entropy', 'model__max_depth': 12, 'model__max_features': 'log2', 'model__n_estimators': 50, 'smote__k_neighbors': 5}\n",
      "Train score is 1.0\n",
      "Test score is 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "pipe_rand_smote = Pipeline([('smote', SMOTE()), ('model', RandomForestClassifier(random_state=0))])\n",
    "\n",
    "param_grid = {\n",
    " \n",
    "    'smote__k_neighbors': [1,2,3,4,5],\n",
    "    'model__n_estimators': [50, 100, 150],\n",
    "    'model__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'model__max_depth' : [10, 11, 12],\n",
    "    'model__criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_rand_smote = GridSearchCV(pipe_rand_smote, param_grid, cv=5, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_rand_smote.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_rand_smote.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_rand_smote.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_rand_smote.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_rand_smote.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rfc data sampling.joblib']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save Data Sampling algorithms - rfc\n",
    "from joblib import dump, load\n",
    "dump(grid_rand_smote, 'rfc data sampling.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with svmsmote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.87\n",
      "Best parameters: {'model__criterion': 'entropy', 'model__max_depth': 11, 'model__max_features': 'log2', 'model__n_estimators': 100, 'svmsmote__k_neighbors': 5}\n",
      "Train score is 0.9895227008149009\n",
      "Test score is 0.830945558739255\n"
     ]
    }
   ],
   "source": [
    "pipe_rand_svmsmote =  Pipeline([('svmsmote', SVMSMOTE()),  ('model', RandomForestClassifier(random_state=0))])\n",
    "\n",
    "param_svmgrid = {\n",
    " \n",
    "    'svmsmote__k_neighbors': [1,2,3,4,5],\n",
    "    'model__n_estimators': [50, 100, 150],\n",
    "    'model__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'model__max_depth' : [10, 11, 12],\n",
    "    'model__criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_rand_svmsmote = GridSearchCV(pipe_rand_svmsmote, param_svmgrid , cv=6, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_rand_svmsmote.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_rand_svmsmote.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_rand_svmsmote.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_rand_svmsmote.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_rand_svmsmote.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rfc svmsmote.joblib']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save Data Sampling algorithms -rfc svmsmote\n",
    "dump(grid_rand_svmsmote, 'rfc svmsmote.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Ensemble Classifier with oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Ensemble Classifier with base estimator - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.59\n",
      "\n",
      "Decision Tree parameters:  {'n_estimators': 100}\n",
      "Decision Tree Performance Train:  0.6515151515151516\n",
      "Decision Tree Performance Test:  0.6190476190476191\n"
     ]
    }
   ],
   "source": [
    "model = EasyEnsembleClassifier(base_estimator=XGBClassifier())\n",
    "\n",
    "#define a list of parameters\n",
    "param_eec = {'n_estimators': [30, 50, 100]}\n",
    "\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#apply grid search\n",
    "grid_eec1 = GridSearchCV(model, param_eec, cv=cv, return_train_score = True, scoring=ftwo_scorer)\n",
    "grid_eec1.fit(X_train, y_train)\n",
    "\n",
    "# Mean Cross Validation Score\n",
    "print(\"Best Mean Cross-validation score: {:.2f}\".format(grid_eec1.best_score_))\n",
    "print()\n",
    "\n",
    "#find best parameters\n",
    "print('Decision Tree parameters: ', grid_eec1.best_params_)\n",
    "\n",
    "# Check test data set performance\n",
    "print(\"Decision Tree Performance Train: \", grid_eec1.score(X_train,y_train))\n",
    "print(\"Decision Tree Performance Test: \", grid_eec1.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['easy ensembli xgb.joblib']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save Data Sampling algorithms - easy ensembli xgb\n",
    "dump(grid_eec1, 'easy ensembli xgb.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Ensemble Classifier with base estimator - Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.58\n",
      "\n",
      "Decision Tree parameters:  {'n_estimators': 30}\n",
      "Decision Tree Performance Train:  0.6403574087862993\n",
      "Decision Tree Performance Test:  0.611111111111111\n"
     ]
    }
   ],
   "source": [
    "eec = EasyEnsembleClassifier(random_state=0)\n",
    "\n",
    "\n",
    "#define a list of parameters\n",
    "param_eec = {'n_estimators': [10, 20, 30]}\n",
    "\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#apply grid search\n",
    "grid_eec = GridSearchCV(eec, param_eec, cv=cv, return_train_score = True, scoring=ftwo_scorer)\n",
    "grid_eec.fit(X_train, y_train)\n",
    "\n",
    "# Mean Cross Validation Score\n",
    "print(\"Best Mean Cross-validation score: {:.2f}\".format(grid_eec.best_score_))\n",
    "print()\n",
    "\n",
    "#find best parameters\n",
    "print('Decision Tree parameters: ', grid_eec.best_params_)\n",
    "\n",
    "# Check test data set performance\n",
    "print(\"Decision Tree Performance Train: \", grid_eec.score(X_train,y_train))\n",
    "print(\"Decision Tree Performance Test: \", grid_eec.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['easy ensembli adab.joblib']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save Data Sampling algorithms - easy ensembli adab\n",
    "dump(grid_eec, 'easy ensembli adab.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost with oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XgBoost with SMOTE Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.88\n",
      "Best parameters: {'model__learning_rate': 0.8, 'model__min_child_weight': 7, 'smote__k_neighbors': 3}\n",
      "Train score is 0.9976798143851509\n",
      "Test score is 0.8096590909090908\n"
     ]
    }
   ],
   "source": [
    "pipe_xgbc_smote = Pipeline([('smote', SMOTE()), \n",
    "                            ('model',XGBClassifier(random_state=0))])\n",
    "\n",
    "param_grid = {\n",
    " \n",
    "    'smote__k_neighbors': [1,2,3,4,5],\n",
    "    'model__learning_rate' : [0.1,0.2,0.6,0.8],\n",
    "    'model__min_child_weight' : [1,3,5,7],\n",
    "   \n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_xgbc_smote = GridSearchCV(pipe_xgbc_smote, param_grid, cv=5, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_xgbc_smote.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_xgbc_smote.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_xgbc_smote.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_xgbc_smote.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_xgbc_smote.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb smote.joblib']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save Data Sampling algorithms - xgb smote\n",
    "dump(grid_xgbc_smote, 'xgb smote.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XgBoost with SMOTE Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.8873\n",
      "Best parameters: {'model__learning_rate': 0.7, 'model__min_child_weight': 8, 'smote__k_neighbors': 2}\n",
      "Train score is 0.9965237543453072\n",
      "Test score is 0.8073654390934843\n"
     ]
    }
   ],
   "source": [
    "pipe_xgbc_smote3 = Pipeline([('smote', SMOTE()), \n",
    "                            ('model',XGBClassifier(random_state=0))])\n",
    "\n",
    "param_grid3 = {\n",
    " \n",
    "    'smote__k_neighbors': [1, 2,3,4],\n",
    "    'model__learning_rate' : [0.7, 0.8, 0.9, 0.95],\n",
    "    'model__min_child_weight' : [5, 6,7, 8],\n",
    "   \n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_xgbc_smote3 = GridSearchCV(pipe_xgbc_smote3, param_grid3, cv=5, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_xgbc_smote3.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.4f}\".format(grid_xgbc_smote3.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_xgbc_smote3.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_xgbc_smote3.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_xgbc_smote3.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XgBoost with SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.88\n",
      "Best parameters: {'model__learning_rate': 0.2, 'model__min_child_weight': 1, 'svmsmote__k_neighbors': 3}\n",
      "Train score is 1.0\n",
      "Test score is 0.8192090395480225\n"
     ]
    }
   ],
   "source": [
    "pipe_xgbc_smote1 = Pipeline([('svmsmote', SVMSMOTE()), \n",
    "                            ('model',XGBClassifier(random_state=0))])\n",
    "\n",
    "param_grid = {\n",
    " \n",
    "    'svmsmote__k_neighbors': [1,2,3,4,5],\n",
    "    'model__learning_rate' : [0.1,0.2,0.6,0.8],\n",
    "    'model__min_child_weight' : [1,3,5,7],\n",
    "   \n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_xgbc_smote1 = GridSearchCV(pipe_xgbc_smote1, param_grid, cv=6, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_xgbc_smote1.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_xgbc_smote1.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_xgbc_smote1.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_xgbc_smote1.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_xgbc_smote1.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb svmsmote.joblib']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save Data Sampling algorithms - xgb svmsmote\n",
    "dump(grid_xgbc_smote1, 'xgb svmsmote.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XgBoost with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.86\n",
      "Best parameters: {'adasyn__n_neighbors': 4, 'model__learning_rate': 0.6, 'model__min_child_weight': 1}\n",
      "Train score is 1.0\n",
      "Test score is 0.8263305322128852\n"
     ]
    }
   ],
   "source": [
    "pipe_xgbc_ada = Pipeline([('adasyn', ADASYN()), \n",
    "                            ('model',XGBClassifier(random_state=0))])\n",
    "\n",
    "param_grid = {\n",
    " \n",
    "    'adasyn__n_neighbors': [1,2,3,4,5],\n",
    "    'model__learning_rate' : [0.1,0.2,0.6,0.8],\n",
    "    'model__min_child_weight' : [1,3,5,7],\n",
    "   \n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_xgbc_ada = GridSearchCV(pipe_xgbc_ada, param_grid, cv=6, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_xgbc_ada.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_xgbc_ada.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_xgbc_ada.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_xgbc_ada.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_xgbc_ada.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb ada.joblib']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save Data Sampling algorithms - xgb ada\n",
    "dump(grid_xgbc_ada, 'xgb ada.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network - MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.83\n",
      "Best parameters: {'alpha': 1e-05, 'solver': 'adam'}\n",
      "Train score is 0.8767772511848341\n",
      "Test score is 0.7879656160458453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlpclf = MLPClassifier(hidden_layer_sizes=(5, 2),random_state=0)\n",
    "\n",
    "param_grid = {'alpha': [1e-5, 1e-4],\n",
    "             'solver' : ['lbfgs', 'sgd', 'adam']}\n",
    "\n",
    "\n",
    "#apply grid search\n",
    "grid_mlpclf = GridSearchCV(mlpclf, param_grid, cv=6, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_mlpclf.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_mlpclf.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_mlpclf.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_mlpclf.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_mlpclf.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neural net.joblib']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save Data Sampling algorithms -neural net\n",
    "dump(grid_mlpclf, 'neural net.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.7145\n",
      "Best parameters: {'model__alpha': 0.0001, 'model__solver': 'adam', 'smote__k_neighbors': 6}\n",
      "Train score is 0.8465346534653465\n",
      "Test score is 0.7195121951219512\n"
     ]
    }
   ],
   "source": [
    "pipe_smotemlp = Pipeline([('smote', SMOTE()), \n",
    "                    ('model',MLPClassifier(hidden_layer_sizes=(5, 2),random_state=0))])\n",
    "\n",
    "param_smotemlp = {\n",
    " \n",
    "    'smote__k_neighbors': [1,2,3,4, 5, 6],\n",
    "     'model__alpha': [1e-5, 1e-4],\n",
    "    'model__solver' : ['lbfgs', 'sgd', 'adam']}\n",
    "\n",
    "#apply grid search\n",
    "grid_smote_mlp = GridSearchCV(pipe_smotemlp, param_smotemlp, cv=5, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_smote_mlp.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.4f}\".format(grid_smote_mlp.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_smote_mlp.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_smote_mlp.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_smote_mlp.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA - Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lda\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/5e/11c73af7335942b9ece20f965271ea632cc26d26d034598502ee4b982251/lda-1.1.0-cp37-cp37m-win_amd64.whl (341kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.13.0 in c:\\users\\jayas\\anaconda3\\lib\\site-packages (from lda) (1.16.5)\n",
      "Collecting pbr<4,>=0.6 (from lda)\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/5d/b077dbf309993d52c1d71e6bf6fe443a8029ea215135ebbe0b1b10e7aefc/pbr-3.1.1-py2.py3-none-any.whl (99kB)\n",
      "Installing collected packages: pbr, lda\n",
      "Successfully installed lda-1.1.0 pbr-3.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.7222\n",
      "Best parameters: {'model__tol': 0.001, 'smote__k_neighbors': 1}\n",
      "Train score is 0.727699530516432\n",
      "Test score is 0.6750572082379862\n"
     ]
    }
   ],
   "source": [
    "pipe_lda = Pipeline([('smote', SMOTE()), \n",
    "                    ('model',LDA())])\n",
    "\n",
    "param_lda = {\n",
    " \n",
    "    'smote__k_neighbors': [1,2,3,4, 5, 6],\n",
    "     'model__tol' : [1.0e-4, 1.0e-3, 1.0e-5, 0.001,0.01],\n",
    "   \n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_smote_lda = GridSearchCV(pipe_lda, param_lda, cv=5, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_smote_lda.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.4f}\".format(grid_smote_lda.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_smote_lda.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_smote_lda.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_smote_lda.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lda smote.joblib']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save Data Sampling algorithms -lda smote\n",
    "dump(grid_smote_lda, 'lda smote.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA with SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.73\n",
      "Best parameters: {'model__tol': 1e-05, 'svmsmote__k_neighbors': 1}\n",
      "Train score is 0.7359924026590694\n",
      "Test score is 0.7040572792362767\n"
     ]
    }
   ],
   "source": [
    "pipe_ldasvm = Pipeline([('svmsmote', SVMSMOTE()), \n",
    "                          ('model',LDA())])\n",
    "\n",
    "param_ldasvm = {\n",
    " \n",
    "    'svmsmote__k_neighbors': [1,2,3,4,5],\n",
    "    'model__tol' : [1.0e-4, 1.0e-3, 1.0e-5, 0.001,0.01],\n",
    "   \n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_svmsmote_lda = GridSearchCV(pipe_ldasvm, param_ldasvm, cv=6, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_svmsmote_lda.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_svmsmote_lda.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_svmsmote_lda.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_svmsmote_lda.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_svmsmote_lda.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lda svmsmote.joblib']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save Data Sampling algorithms -lda svmsmote\n",
    "dump(param_ldasvm, 'lda svmsmote.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking top data sampling algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.86\n",
      "\n",
      "Best parameters:  {'final_estimator__max_depth': 3, 'stack_method': 'predict_proba'}\n",
      "Train score :  1.0\n",
      "Test score :  0.802292263610315\n"
     ]
    }
   ],
   "source": [
    "# Stacking algorithm using the top models\n",
    "sclf_datasamp = StackingClassifier(estimators=\n",
    "                                 [('radmf', grid_rand_smote.best_estimator_),\n",
    "                                  ('xgbcsvmsmote', grid_xgbc_smote1.best_estimator_), \n",
    "                                 ('xgbcsmote', grid_xgbc_smote.best_estimator_),\n",
    "                              ], final_estimator=DecisionTreeClassifier(random_state=0))\n",
    "\n",
    "sclfdatasamp_param = {\n",
    "              'final_estimator__max_depth': range(2,20),\n",
    "              'stack_method':['auto', 'predict_proba']\n",
    "             }\n",
    "\n",
    "sclf_datasamp_grid = GridSearchCV(sclf_datasamp, sclfdatasamp_param,cv=6, return_train_score=True, scoring=ftwo_scorer)\n",
    "sclf_datasamp_grid.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Mean Cross Validation Score\n",
    "print(\"Best Mean Cross-validation score: {:.2f}\".format(sclf_datasamp_grid.best_score_))\n",
    "print()\n",
    "\n",
    "#find best parameters\n",
    "print('Best parameters: ',sclf_datasamp_grid.best_params_)\n",
    "\n",
    "\n",
    "# Check test data set performance\n",
    "print(\"Train score : \",sclf_datasamp_grid.score(X_train,y_train))\n",
    "print(\"Test score : \",sclf_datasamp_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stacking data sampl.joblib']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save Data Sampling algorithms -Stacking\n",
    "dump(sclf_datasamp_grid, 'Stacking data sampl.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking top 4 (cost sensitive and data sampling ) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve etc cost sensit\n",
    "from joblib import dump, load\n",
    "etc_grid_bal = load('etc cost.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve XG boost SVM\n",
    "from joblib import dump, load\n",
    "grid_xgbc_smote1 = load('xgb svmsmote.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve rfc smote\n",
    "grid_rand_smote = load('rfc data sampling.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve xgb cost\n",
    "grid_xgboost_bal = load('xgb cost.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.86\n",
      "\n",
      "Best parameters:  {'final_estimator__C': 1, 'stack_method': 'auto'}\n",
      "Train score :  1.0\n",
      "Test score :  0.8262108262108261\n"
     ]
    }
   ],
   "source": [
    "# Stacking algorithm using the top models\n",
    "sclf8 = StackingClassifier(estimators=\n",
    "                                 [('etc', etc_grid_bal.best_estimator_),\n",
    "                                  ('rfc', grid_rand_smote.best_estimator_),\n",
    "                                 ('xgb cost', grid_xgboost_bal.best_estimator_),\n",
    "                                ('xgbcsvmsmote',grid_xgbc_smote1.best_estimator_),\n",
    "                              ], final_estimator=LogisticRegression())\n",
    "\n",
    "sclf_param8 = {\n",
    "            'final_estimator__C' : [0.001, 0.01, 0.1, 1],\n",
    "              'stack_method':['auto', 'predict_proba']\n",
    "             }\n",
    "\n",
    "sclf_grid8 = GridSearchCV(sclf8, sclf_param8,cv=6, return_train_score=True, scoring=ftwo_scorer)\n",
    "sclf_grid8.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Mean Cross Validation Score\n",
    "print(\"Best Mean Cross-validation score: {:.2f}\".format(sclf_grid8.best_score_))\n",
    "print()\n",
    "\n",
    "#find best parameters\n",
    "print('Best parameters: ',sclf_grid8.best_params_)\n",
    "\n",
    "\n",
    "# Check test data set performance\n",
    "print(\"Train score : \",sclf_grid8.score(X_train,y_train))\n",
    "print(\"Test score : \",sclf_grid8.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking overall top models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.86\n",
      "\n",
      "Best parameters:  {'final_estimator__C': 1, 'stack_method': 'auto'}\n",
      "Train score :  1.0\n",
      "Test score :  0.8092485549132947\n"
     ]
    }
   ],
   "source": [
    "# Stacking algorithm using the top models\n",
    "sclf8 = StackingClassifier(estimators=\n",
    "                           [('rfc data sampling', grid_rand_smote.best_estimator_),\n",
    "                                  ('etc', etc_grid_bal.best_estimator_), \n",
    "                                  ('xgb svmsmote',grid_xgbc_smote1.best_estimator_),\n",
    "                              ], final_estimator=LogisticRegression(class_weight = {0: 1, 1: 1}))\n",
    "                           \n",
    "                           \n",
    "sclf_param8 = {\n",
    "            'final_estimator__C' : [0.001, 0.01, 0.1, 1],\n",
    "              'stack_method':['auto', 'predict_proba']\n",
    "             }\n",
    "\n",
    "sclf_grid8 = GridSearchCV(sclf8, sclf_param8,cv=6, return_train_score=True, scoring=ftwo_scorer)\n",
    "sclf_grid8.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Mean Cross Validation Score\n",
    "print(\"Best Mean Cross-validation score: {:.2f}\".format(sclf_grid8.best_score_))\n",
    "print()\n",
    "\n",
    "#find best parameters\n",
    "print('Best parameters: ',sclf_grid8.best_params_)\n",
    "\n",
    "\n",
    "# Check test data set performance\n",
    "print(\"Train score : \",sclf_grid8.score(X_train,y_train))\n",
    "print(\"Test score : \",sclf_grid8.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting of best overall models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve decision tree\n",
    "grid_dtree = load('dtree basic.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve\n",
    "grid_xgbc_ada = load('xgb ada.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve bagg\n",
    "grid_param_dt_bag = load('bagging cost1.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.87\n",
      "\n",
      "Best parameters:  {'voting': 'soft'}\n",
      "Train score :  1.0\n",
      "Test score :  0.8189655172413792\n"
     ]
    }
   ],
   "source": [
    "vclf_all = VotingClassifier(estimators=\n",
    "                               [('dtree basic', grid_dtree.best_estimator_), \n",
    "                                   ('xgb svmsmote',grid_xgbc_smote1.best_estimator_),\n",
    "                                  ('rfc data sampling', grid_rand_smote.best_estimator_),\n",
    "                                  ('etc cost', etc_grid_bal.best_estimator_), \n",
    "                                ('xgb adn', grid_xgbc_ada.best_estimator_),\n",
    "                                 ('bagg', grid_param_dt_bag.best_estimator_)\n",
    "                              ], )\n",
    "vclf_all_param = {\n",
    "              'voting' : ['hard','soft'],\n",
    "             }\n",
    "vclf_all_grid = GridSearchCV(vclf_all, vclf_all_param, cv=6, return_train_score=True, scoring=ftwo_scorer)\n",
    "vclf_all_grid.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross Validation Score\n",
    "print(\"Best Mean Cross-validation score: {:.2f}\".format(vclf_all_grid.best_score_))\n",
    "print()\n",
    "\n",
    "#find best parameters\n",
    "print('Best parameters: ',vclf_all_grid.best_params_)\n",
    "\n",
    "\n",
    "# Check test data set performance\n",
    "print(\"Train score : \",vclf_all_grid.score(X_train,y_train))\n",
    "print(\"Test score : \",vclf_all_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24846, 29)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=test.drop(['Id'], axis=1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Transformations\n",
    "X_test=data_preprocess.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model - SMOTE RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_model =Pipeline([('smote', SMOTE(k_neighbors = 5)), \n",
    "                        ('model', RandomForestClassifier(random_state=0, n_estimators = 50, \n",
    "                                                         max_features = 'log2', max_depth =12,criterion = 'entropy'))])\n",
    "   \n",
    "kaggle_model.fit(X_train,y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "test_data_labels = kaggle_model.predict(X_test)\n",
    "\n",
    "# Create predictions to be submitted!\n",
    "pd.DataFrame({'Id': test.Id, 'Target': test_data_labels}).to_csv('solution_base_rfcsmote.csv', index =False)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model - SVMSMOTE XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_model3 =Pipeline([('svmsmote', SVMSMOTE(k_neighbors = 3)), \n",
    "                            ('model',XGBClassifier(random_state=0, learning_rate = 0.2, min_child_weight = 1))])\n",
    "   \n",
    "kaggle_model3.fit(X_train,y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "test_data_labels = kaggle_model3.predict(X_test)\n",
    "\n",
    "# Create predictions to be submitted!\n",
    "pd.DataFrame({'Id': test.Id, 'Target': test_data_labels}).to_csv('solution_xgbost_svm.csv', index =False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model - top data sampling models with stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_model5 = StackingClassifier(stack_method = 'predict_proba', estimators=\n",
    "                                 [('radmf', grid_rand_smote.best_estimator_),\n",
    "                                  ('xgbcsvmsmote', grid_xgbc_smote1.best_estimator_), \n",
    "                                 ('xgbcsmote', grid_xgbc_smote.best_estimator_),\n",
    "                              ], final_estimator=DecisionTreeClassifier(random_state=0, max_depth = 3 ))\n",
    "\n",
    "kaggle_model5.fit(X_train,y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "test_data_labels = kaggle_model5.predict(X_test)\n",
    "\n",
    "# Create predictions to be submitted!\n",
    "pd.DataFrame({'Id': test.Id, 'Target': test_data_labels}).to_csv('solution_stackdatasamp.csv', index =False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_model6 = StackingClassifier(stack_method = 'auto', estimators=\n",
    "                                 [('radmf', grid_rand_smote.best_estimator_),\n",
    "                                  ('xgbcsvmsmote', grid_xgbc_smote1.best_estimator_), \n",
    "                                 ('xgbcsmote', grid_xgbc_smote.best_estimator_),\n",
    "                              ], final_estimator=DecisionTreeClassifier(random_state=0, max_depth = 3 ))\n",
    "\n",
    "kaggle_model6.fit(X_train,y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "test_data_labels = kaggle_model6.predict(X_test)\n",
    "\n",
    "# Create predictions to be submitted!\n",
    "pd.DataFrame({'Id': test.Id, 'Target': test_data_labels}).to_csv('solution_stackdatasamp_auto.csv', index =False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model - overall models with stacking (final estimator - logis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_model11 = StackingClassifier(stack_method = 'auto', estimators=\n",
    "                                  [('etc', etc_grid_bal.best_estimator_),\n",
    "                                  ('rfc', grid_rand_smote.best_estimator_),\n",
    "                                 ('xgb cost', grid_xgboost_bal.best_estimator_),\n",
    "                                ('xgbcsvmsmote',grid_xgbc_smote1.best_estimator_),\n",
    "                              ], final_estimator=LogisticRegression(C = 1))\n",
    "\n",
    "\n",
    "kaggle_model11.fit(X_train,y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "test_data_labels = kaggle_model11.predict(X_test)\n",
    "\n",
    "# Create predictions to be submitted!\n",
    "pd.DataFrame({'Id': test.Id, 'Target': test_data_labels}).to_csv('solution_overall top models - Stacklog.csv', index =False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model - overall models with stacking (final estimator - logis with class weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_model21 = StackingClassifier(stack_method = 'auto', estimators=\n",
    "                           [('rfc data sampling', grid_rand_smote.best_estimator_),\n",
    "                                  ('etc', etc_grid_bal.best_estimator_), \n",
    "                                  ('xgb svmsmote',grid_xgbc_smote1.best_estimator_),\n",
    "                              ], final_estimator=LogisticRegression(C = 1, class_weight = {0: 1, 1: 1}))\n",
    "\n",
    "\n",
    "kaggle_model21.fit(X_train,y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "test_data_labels = kaggle_model21.predict(X_test)\n",
    "\n",
    "# Create predictions to be submitted!\n",
    "pd.DataFrame({'Id': test.Id, 'Target': test_data_labels}).to_csv('solution_overall top models - Stacklog with class weights.csv', index =False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model - overall models with voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_model13 = VotingClassifier(voting = 'soft',estimators=\n",
    "                               [('dtree basic', grid_dtree.best_estimator_), \n",
    "                                   ('xgb svmsmote',grid_xgbc_smote1.best_estimator_),\n",
    "                                  ('rfc data sampling', grid_rand_smote.best_estimator_),\n",
    "                                  ('etc cost', etc_grid_bal.best_estimator_), \n",
    "                                ('xgb adn', grid_xgbc_ada.best_estimator_),\n",
    "                                 ('bagg', grid_param_dt_bag.best_estimator_)\n",
    "                              ], )\n",
    "kaggle_model13.fit(X_train,y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "test_data_labels = kaggle_model13.predict(X_test)\n",
    "\n",
    "# Create predictions to be submitted!\n",
    "pd.DataFrame({'Id': test.Id, 'Target': test_data_labels}).to_csv('solution_Voting overall.csv', index =False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buan6341_2020",
   "language": "python",
   "name": "buan6341_2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
