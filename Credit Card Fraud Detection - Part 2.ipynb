{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional File No.1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <font color='purple'> \n",
    "    \n",
    "  This file contains some Cost Sensitive Algorithms and some Data Sampling Algorithms. These algorithms are run here and then loaded into the oringinal file using joblib inorder take advantage of parallel running of algorithms as this saves time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Sensitive Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.86\n",
      "\n",
      "XG Boost parameters:  {'learning_rate': 0.6, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 50, 'subsample': 1}\n",
      "Train score of XG Boost:  1.0\n",
      "Test score of XG Boost:  0.8213256484149856\n"
     ]
    }
   ],
   "source": [
    "xgbc= XGBClassifier(random_state=0,early_stopping_rounds=2,objective= 'binary:logistic',class_weight='balanced')\n",
    "xgbc_param = {\n",
    "              'max_depth' : [6,7,8,9],\n",
    "              'n_estimators' : [50,100,150],\n",
    "              'learning_rate' : [0.4, 0.6,0.8],\n",
    "               'min_child_weight' : [1,3],\n",
    "                'subsample':[0.8,0.9,1]\n",
    "             }\n",
    "xgbc_grid_bal = GridSearchCV(xgbc, xgbc_param,cv=5, return_train_score=True,scoring=ftwo_scorer)\n",
    "xgbc_grid_bal.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross Validation Score\n",
    "print(\"Best Mean Cross-validation score: {:.2f}\".format(xgbc_grid_bal.best_score_))\n",
    "print()\n",
    "\n",
    "#find best parameters\n",
    "print('XG Boost parameters: ',xgbc_grid_bal.best_params_)\n",
    "\n",
    "\n",
    "# Check test data set performance\n",
    "print(\"Train score of XG Boost: \",xgbc_grid_bal.score(X_train,y_train))\n",
    "print(\"Test score of XG Boost: \",xgbc_grid_bal.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XGboost_costsensitive1.joblib']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save XGBoost Cost sensitive\n",
    "dump(xgbc_grid_bal, 'XGboost_costsensitive1.joblib') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'scale_pos_weight': 75}\n",
      "Best Mean cross-validation score: 0.85\n",
      "Train score of XG Boost:  1.0\n",
      "Test score of XG Boost:  0.8189655172413792\n"
     ]
    }
   ],
   "source": [
    "xgboost = XGBClassifier()\n",
    "param_grid = {\n",
    "    \n",
    "    'scale_pos_weight': [1, 2, 5, 50, 75, 100],\n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_xgboost_bal = GridSearchCV(xgboost, param_grid, cv=6, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_xgboost_bal.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_xgboost_bal.best_params_))\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_xgboost_bal.best_score_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(\"Train score of XG Boost: \",grid_xgboost_bal.score(X_train,y_train))\n",
    "print(\"Test score of XG Boost: \",grid_xgboost_bal.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling Algorithms - Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.65\n",
      "Best parameters: {'model__C': 200, 'model__penalty': 'l2', 'smote__k_neighbors': 5}\n",
      "Train score is 0.6663872590108969\n",
      "Test score is 0.6412825651302605\n"
     ]
    }
   ],
   "source": [
    "# GridSearch with oversampling\n",
    "pipe_log_smote = Pipeline([('smote', SMOTE()), ('model',LogisticRegression())])\n",
    "\n",
    "param_grid = {\n",
    "    # try different feature engineering parameters\n",
    "    'smote__k_neighbors': [1,2,3,4,5],\n",
    "    'model__C':  [5, 8, 10, 20, 100, 150, 200],\n",
    "    'model__penalty':  ['l1','l2'],\n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_smote_log = GridSearchCV(pipe_log_smote, param_grid, cv=5, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_smote_log.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_smote_log.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_smote_log.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_smote_log.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_smote_log.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Log_Smote.joblib']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save XGBoost data sampling\n",
    "dump(grid_smote_log, 'Log_Smote.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree with oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.81\n",
      "Best parameters: {'model__max_depth': 34, 'svmsmote__k_neighbors': 2}\n",
      "Train score is 1.0\n",
      "Test score is 0.7596685082872927\n"
     ]
    }
   ],
   "source": [
    "pipe_dec_svmsmote = Pipeline([('svmsmote', SVMSMOTE()), ('model', DecisionTreeClassifier(random_state=0))])\n",
    "\n",
    "param_grid = {\n",
    "    # try different feature engineering parameters\n",
    "    'svmsmote__k_neighbors': [1,2,3,4,5],\n",
    "    'model__max_depth': range(3,36),\n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_smote_deci1 = GridSearchCV(pipe_dec_svmsmote, param_grid, cv=5, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_smote_deci1.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_smote_deci1.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_smote_deci1.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_smote_deci1.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_smote_deci1.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dtree_Smote.joblib']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save dtree data sampling\n",
    "dump(grid_smote_deci1, 'dtree_Smote.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with SVMsmote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.84\n",
      "Best parameters: {'model__criterion': 'entropy', 'model__max_depth': 17, 'model__splitter': 'best', 'svmsmote__k_neighbors': 2}\n",
      "Train score is 1.0\n",
      "Test score is 0.782967032967033\n"
     ]
    }
   ],
   "source": [
    "pipe_dec_svmsmote = Pipeline([('svmsmote', SVMSMOTE()), ('model', DecisionTreeClassifier(random_state=0))])\n",
    "\n",
    "param_grid = {\n",
    "    # try different feature engineering parameters\n",
    "    'svmsmote__k_neighbors': [1,2,3],\n",
    "    'model__max_depth': range(3,36),\n",
    "     'model__criterion': ['gini', 'entropy'],\n",
    "     'model__splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_svmsmote_deci1 = GridSearchCV(pipe_dec_svmsmote, param_grid, cv=6, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_svmsmote_deci1.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_svmsmote_deci1.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_svmsmote_deci1.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_svmsmote_deci1.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_svmsmote_deci1.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dtree_SVMSmote.joblib']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save dtree data sampling\n",
    "from joblib import dump, load\n",
    "dump(grid_svmsmote_deci1, 'dtree_SVMSmote.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.71\n",
      "Best parameters: {'adasyn__n_neighbors': 2, 'model__max_depth': 34}\n",
      "Train score is 0.9873708381171066\n",
      "Test score is 0.7179487179487181\n"
     ]
    }
   ],
   "source": [
    "pipe_deci_adasyn = Pipeline([('adasyn', ADASYN()), ('model', DecisionTreeClassifier(random_state=0))])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    # try different feature engineering parameters\n",
    "    'adasyn__n_neighbors': [1,2,3,4,5],\n",
    "    'model__max_depth': range(3,36),\n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_adasyn_deci = GridSearchCV(pipe_deci_adasyn, param_grid, cv=8, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_adasyn_deci.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_adasyn_deci.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_adasyn_deci.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_adasyn_deci.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_adasyn_deci.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dtree_ADASmote.joblib']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save dtree data sampling\n",
    "dump(grid_adasyn_deci, 'dtree_ADASmote.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.79\n",
      "Best parameters: {'model__n_neighbors': 4, 'smote__k_neighbors': 3}\n",
      "Train score is 0.9587513935340023\n",
      "Test score is 0.7772020725388602\n"
     ]
    }
   ],
   "source": [
    "pipe_knn_smote = Pipeline([('smote', SMOTE()), ('model',KNeighborsClassifier())])\n",
    "\n",
    "param_grid = {\n",
    "    # try different feature engineering parameters\n",
    "    'smote__k_neighbors': [1,2,3,4,5],\n",
    "    'model__n_neighbors': range(2,45),\n",
    "}\n",
    "\n",
    "#apply grid search\n",
    "grid_smote_knn = GridSearchCV(pipe_knn_smote, param_grid, cv=5, n_jobs=2, scoring=ftwo_scorer)\n",
    "grid_smote_knn.fit(X_train,y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_smote_knn.best_score_))\n",
    "\n",
    "#find best parameters\n",
    "print(\"Best parameters: {}\".format(grid_smote_knn.best_params_))\n",
    "\n",
    "# Check test data set performance\n",
    "print(f'Train score is {grid_smote_knn.score(X_train,y_train)}')\n",
    "print(f'Test score is {grid_smote_knn.score(X_val,y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn_Smote.joblib']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Save knn data sampling\n",
    "dump(grid_smote_knn, 'knn_Smote.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipe_SVCL_smote = Pipeline([('smote', SMOTE()), ('model', SVC(kernel = 'linear'))]) <br>\n",
    "\n",
    "param_grid = {<br>\n",
    "    # try different feature engineering parameters<br>\n",
    "    'smote__k_neighbors': [1,2,3,4,5],<br>\n",
    "    'model__C': [0.8, 1, 1.5, 10, 15],<br>\n",
    "    'model__gamma':[0.0001,0.001,0.1],<br>\n",
    "    \n",
    "}<br>\n",
    "\n",
    "#apply grid search<br>\n",
    "grid_SVCL_smote = GridSearchCV(pipe_SVCL_smote, param_grid, cv=5, n_jobs=2, scoring=ftwo_scorer)<br>\n",
    "grid_SVCL_smote.fit(X_train,y_train)<br>\n",
    "\n",
    "Mean Cross validation Score<br>\n",
    "print(\"Best Mean cross-validation score: {:.2f}\".format(grid_SVCL_smote.best_score_))<br>\n",
    "\n",
    "find best parameters<br>\n",
    "print(\"Best parameters: {}\".format(grid_SVCL_smote.best_params_))<br>\n",
    "\n",
    "Check test data set performance<br>\n",
    "print(f'Train score is {grid_SVCL_smote.score(X_train,y_train)}')<br>\n",
    "print(f'Test score is {grid_SVCL_smote.score(X_val,y_val)}')<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> <b> ** Since SVC code took more than 12 hrs to run, it is not run <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24846, 29)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=test.drop(['Id'], axis=1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Transformations\n",
    "X_test=data_preprocess.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_model = XGBClassifier(random_state=0,early_stopping_rounds=2,objective= 'binary:logistic', \n",
    "                             learning_rate = 0.6, max_depth = 8, min_child_weight = 1, n_estimators = 50,\n",
    "                             subsample = 1)\n",
    "kaggle_model.fit(X_train,y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "test_data_labels = kaggle_model.predict(X_test)\n",
    "\n",
    "# Create predictions to be submitted!\n",
    "pd.DataFrame({'Id': test.Id, 'Target': test_data_labels}).to_csv('solution_base_xgb_normal.csv', index =False)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buan6341_2020",
   "language": "python",
   "name": "buan6341_2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
